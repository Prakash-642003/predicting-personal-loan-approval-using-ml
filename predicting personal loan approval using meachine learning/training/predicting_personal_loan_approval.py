# -*- coding: utf-8 -*-
"""predicting personal loan approval

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ihpGQk9hg50D2gtA2p79RqOu5cuDlzTg
"""

# importing required lib

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

# checking for available style

plt.style.available

#applying styles to notebook

plt.style.use('fivethirtyeight')

# reading csv data

df = pd.read_csv('/content/train_u6lujuX_CVtuZ9i.csv')
df

# checking data type

df.info()

"""
types of analysis
1)univeriate analysis
2)Birvariate analysis
3)multivariate analysis
4)descriptive analysis / statistics
"""

# univariate analysis - extracting info from a single column

# checking data distribution
plt.subplot(121)
sns.displot(df['Gender'])
plt.sublplot(132)
sns.displot(df['Loan_Status'])

# creating dummy data for categorical values
df_cat =df.select_dtypes(include='object')
df_cat.head

for i,j in enumerate(df_cat):
 print(j)
 print(i)

# visualizing counts in each variable
7
for i,j in enumerate(df_cat):
  plt.subplot(1,3,i+1)
  sns.countplot(df[j])

# Bivariate analysis - extracting info from a double column

#visualizing the relation between Loan_ID,Gender,LoanAmount & Married

plt.subplot(131)
sns.countplot(df['Married'])

df['LoanAmount'].max

# finding relation between Gender_& LoanAmount

pd.crosstab(df['Gender'],df['LoanAmount'])

# Finding corr

sns.heatmap(df.corr())

#Descriptive analysis - descriptive stat

df.describe(include='all')

# data preprocessing

# finding the shape of the data
df.shape

#finding null values

df.isnull().sum()

#finding dtype
df.info()

# finding outliers

sns.boxplot(df['ApplicantIncome'])

# finding the count of outliers

#IQR = q3-q1....., ub =q3+(1.5*IQR),lb =q1-(1.5*IQR)

q1 = np.quantile(df['CoapplicantIncome'],0.25)
q3 = np.quantile(df['CoapplicantIncome'],0.75)

print('Q1={}'.format(q1))
print('Q3={}'.format(q3))

IQR = q3-q1

print('IQR value is{}'.format(IQR))

upperBound = q3+(1.5*IQR)
lowerBound = q1-(1.5*IQR)

print('the upper bound value is {} & the lower bound value is{}'.format(upperBound,lowerBound))

print('skwed data :',len(df[df['CoapplicantIncome']>upperBound]))

# handling outliers

from scipy import stats

plt.figure(figsize=(10,4))
plt.subplot(131)
sns.displot(df['CoapplicantIncome'])
plt.subplot(132)
stats.probplot(np.log(df['CoapplicantIncome']),plot=plt)
plt.subplot(133)
sns.displot(np.log(df['CoapplicantIncome']))

stats.probplot(np.log(df['CoapplicantIncome']),plot=plt)

# transforming normal value to log values
df['CoapplicantIncome']=np.log(df['CoapplicantIncome'])

df.head()

# encoding
# encoding with list comp
df['Gender'] = [0 if x=='LOW' else 1 if x== 'NORMAL'else 2 for x in df['Gender']]

# encoding with replace method
df['Gender'] = df['Gender'].replace({'F':0,'M':1})

df.head()

# spliting dep & Indep variable

x = df.drop('ApplicantIncome',axis=1)
x.head()

y = df['ApplicantIncome']
y

# simple linear reg

#import necessary lib

import numpy as np
import pandas as pd

# reading the data

df =pd.read_csv('/content/train_u6lujuX_CVtuZ9i.csv')
df.head()

# checking the data type

df.info()

# descriptive stat

df.describe()

# checking null values

df.isnull().sum()

# visualizing data points

import matplotlib.pyplot as plt

plt.scatter(df['ApplicantIncome'],df['LoanAmount'])

# independent variable

x = df.iloc[:,:2]
x.head()

# dependent variable

y = df.iloc[:,2:]
y.head()

# spilt training & testing
from sklearn.model_selection import train_test_split

xtrain, xtest, ytrain, ytest = train_test_split(x,y,test_size=0.3,random_state=11)

print(xtrain.shape)
print(xtest.shape)

# Model building

from sklearn.linear_model import LinearRegression

lr = LinearRegression()

lr.fit(xtrain,ytrain)

ypred = lr.predict(xtest)

from sklearn.metrics import r2_score